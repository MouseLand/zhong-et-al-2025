{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0ebf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cbd18",
   "metadata": {},
   "source": [
    "# Download all data from Figshare\n",
    "### Make sure there is at least 1320 GB empty space (420GB for raw data + 900GB for processed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cff48",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "E:\\Zhong-et-2025\\beh\\Beh_naive_test1.npy\n",
      "Beh_naive_test1.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_naive_test2.npy\n",
      "Beh_naive_test2.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_naive_test3.npy\n",
      "Beh_naive_test3.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_test1.npy\n",
      "Beh_sup_test1.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_test2.npy\n",
      "Beh_sup_test2.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_test3.npy\n",
      "Beh_sup_test3.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_train1_after_learning.npy\n",
      "Beh_sup_train1_after_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_train1_before_learning.npy\n",
      "Beh_sup_train1_before_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_train2_after_learning.npy\n",
      "Beh_sup_train2_after_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_sup_train2_before_learning.npy\n",
      "Beh_sup_train2_before_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_test1_after_grating.npy\n",
      "Beh_test1_after_grating.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_test1_before_grating.npy\n",
      "Beh_test1_before_grating.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_test2_after_grating.npy\n",
      "Beh_test2_after_grating.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_test2_before_grating.npy\n",
      "Beh_test2_before_grating.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_train1_after_grating.npy\n",
      "Beh_train1_after_grating.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_train1_before_grating.npy\n",
      "Beh_train1_before_grating.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_test1.npy\n",
      "Beh_unsup_test1.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_test2.npy\n",
      "Beh_unsup_test2.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_test3.npy\n",
      "Beh_unsup_test3.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_train1_after_learning.npy\n",
      "Beh_unsup_train1_after_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_train1_before_learning.npy\n",
      "Beh_unsup_train1_before_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_train2_after_learning.npy\n",
      "Beh_unsup_train2_after_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\Beh_unsup_train2_before_learning.npy\n",
      "Beh_unsup_train2_before_learning.npy\n",
      "E:\\Zhong-et-2025\\beh\\example_bef_and_aft_learning_behavior.npy\n",
      "example_bef_and_aft_learning_behavior.npy\n",
      "E:\\Zhong-et-2025\\beh\\Imaging_Exp_info.npy\n",
      "Imaging_Exp_info.npy\n",
      "E:\\Zhong-et-2025\\beh\\Unsupervised_pretraining_behavior\\Beh_no_pretrain.npy\n",
      "Beh_no_pretrain.npy\n",
      "E:\\Zhong-et-2025\\beh\\Unsupervised_pretraining_behavior\\Beh_pretrain_on_grat_image.npy\n",
      "Beh_pretrain_on_grat_image.npy\n",
      "E:\\Zhong-et-2025\\beh\\Unsupervised_pretraining_behavior\\Beh_pretrain_on_nat_image.npy\n",
      "Beh_pretrain_on_nat_image.npy\n",
      "E:\\Zhong-et-2025\\retinotopy\\areas.npz\n",
      "areas.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR10_2022_07_21_trans.npz\n",
      "DR10_2022_07_21_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR10_2022_07_28_trans.npz\n",
      "DR10_2022_07_28_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR10_2022_07_30_trans.npz\n",
      "DR10_2022_07_30_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ13_2024_05_15_trans.npz\n",
      "LZ13_2024_05_15_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ13_2024_05_16_trans.npz\n",
      "LZ13_2024_05_16_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ13_2024_05_28_trans.npz\n",
      "LZ13_2024_05_28_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR10_2022_07_12_trans.npz\n",
      "DR10_2022_07_12_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ13_2024_05_29_trans.npz\n",
      "LZ13_2024_05_29_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR10_2022_07_19_trans.npz\n",
      "DR10_2022_07_19_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ16_2024_05_18_trans.npz\n",
      "LZ16_2024_05_18_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ16_2024_05_19_trans.npz\n",
      "LZ16_2024_05_19_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ16_2024_05_31_trans.npz\n",
      "LZ16_2024_05_31_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\LZ16_2024_06_01_trans.npz\n",
      "LZ16_2024_06_01_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR10_2022_07_29_trans.npz\n",
      "DR10_2022_07_29_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX104_2022_10_12_trans.npz\n",
      "TX104_2022_10_12_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR15_2022_10_09_trans.npz\n",
      "DR15_2022_10_09_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR15_2022_10_19_trans.npz\n",
      "DR15_2022_10_19_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX104_2022_10_20_trans.npz\n",
      "TX104_2022_10_20_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR15_2022_10_20_trans.npz\n",
      "DR15_2022_10_20_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR15_2022_11_02_trans.npz\n",
      "DR15_2022_11_02_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\DR15_2022_11_03_trans.npz\n",
      "DR15_2022_11_03_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX105_2022_11_05_trans.npz\n",
      "TX105_2022_11_05_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX105_2022_10_08_trans.npz\n",
      "TX105_2022_10_08_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX105_2022_10_19_trans.npz\n",
      "TX105_2022_10_19_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX105_2022_10_21_trans.npz\n",
      "TX105_2022_10_21_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX105_2022_11_08_trans.npz\n",
      "TX105_2022_11_08_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2023_12_12_trans.npz\n",
      "TX119_2023_12_12_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_01_05_trans.npz\n",
      "TX108_2023_01_05_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2023_12_13_trans.npz\n",
      "TX119_2023_12_13_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2023_12_14_trans.npz\n",
      "TX119_2023_12_14_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_03_13_trans.npz\n",
      "TX108_2023_03_13_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_04_01_trans.npz\n",
      "TX108_2023_04_01_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2023_12_23_trans.npz\n",
      "TX119_2023_12_23_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_03_25_trans.npz\n",
      "TX108_2023_03_25_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_03_22_trans.npz\n",
      "TX108_2023_03_22_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_04_07_trans.npz\n",
      "TX108_2023_04_07_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2023_12_24_trans.npz\n",
      "TX119_2023_12_24_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX108_2023_04_04_trans.npz\n",
      "TX108_2023_04_04_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX109_2023_03_16_trans.npz\n",
      "TX109_2023_03_16_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2024_01_06_trans.npz\n",
      "TX119_2024_01_06_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX109_2023_03_27_trans.npz\n",
      "TX109_2023_03_27_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2024_01_07_trans.npz\n",
      "TX119_2024_01_07_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2023_12_18_trans.npz\n",
      "TX123_2023_12_18_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX109_2023_04_07_trans.npz\n",
      "TX109_2023_04_07_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2023_12_20_trans.npz\n",
      "TX123_2023_12_20_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX109_2023_04_18_trans.npz\n",
      "TX109_2023_04_18_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX119_2024_01_09_trans.npz\n",
      "TX119_2024_01_09_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX109_2023_05_12_trans.npz\n",
      "TX109_2023_05_12_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2023_12_21_trans.npz\n",
      "TX123_2023_12_21_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX109_2023_05_13_trans.npz\n",
      "TX109_2023_05_13_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2024_01_02_trans.npz\n",
      "TX123_2024_01_02_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2024_01_03_trans.npz\n",
      "TX123_2024_01_03_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2024_01_15_trans.npz\n",
      "TX123_2024_01_15_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2024_01_16_trans.npz\n",
      "TX123_2024_01_16_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX123_2024_01_17_trans.npz\n",
      "TX123_2024_01_17_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX124_2023_12_23_trans.npz\n",
      "TX124_2023_12_23_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX124_2023_12_24_trans.npz\n",
      "TX124_2023_12_24_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX124_2023_12_26_trans.npz\n",
      "TX124_2023_12_26_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX139_2024_05_18_trans.npz\n",
      "TX139_2024_05_18_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX139_2024_05_31_trans.npz\n",
      "TX139_2024_05_31_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX140_2024_05_31_trans.npz\n",
      "TX140_2024_05_31_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX60_2021_04_10_trans.npz\n",
      "TX60_2021_04_10_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX60_2021_05_04_trans.npz\n",
      "TX60_2021_05_04_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX60_2021_06_07_trans.npz\n",
      "TX60_2021_06_07_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX60_2021_06_22_trans.npz\n",
      "TX60_2021_06_22_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX83_2022_08_17_trans.npz\n",
      "TX83_2022_08_17_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX60_2021_06_21_trans.npz\n",
      "TX60_2021_06_21_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX83_2022_08_31_trans.npz\n",
      "TX83_2022_08_31_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX61_2021_06_07_trans.npz\n",
      "TX61_2021_06_07_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX61_2021_06_19_trans.npz\n",
      "TX61_2021_06_19_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX61_2021_06_20_trans.npz\n",
      "TX61_2021_06_20_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX88_2022_06_17_trans.npz\n",
      "TX88_2022_06_17_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX61_2021_06_23_trans.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX61_2021_06_23_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX61_2021_06_25_trans.npz\n",
      "TX61_2021_06_25_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX83_2022_08_29_trans.npz\n",
      "TX83_2022_08_29_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX85_2022_06_14_trans.npz\n",
      "TX85_2022_06_14_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX85_2022_06_17_trans.npz\n",
      "TX85_2022_06_17_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX88_2022_06_13_trans.npz\n",
      "TX88_2022_06_13_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_05_04_trans.npz\n",
      "VR2_2021_05_04_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX88_2022_06_20_trans.npz\n",
      "TX88_2022_06_20_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX88_2022_07_15_trans.npz\n",
      "TX88_2022_07_15_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX88_2022_07_19_trans.npz\n",
      "TX88_2022_07_19_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\TX88_2022_07_22_trans.npz\n",
      "TX88_2022_07_22_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_03_20_trans.npz\n",
      "VR2_2021_03_20_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_04_06_trans.npz\n",
      "VR2_2021_04_06_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_04_11_trans.npz\n",
      "VR2_2021_04_11_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_04_28_trans.npz\n",
      "VR2_2021_04_28_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_04_29_trans.npz\n",
      "VR2_2021_04_29_trans.npz\n",
      "E:\\Zhong-et-2025\\retinotopy\\VR2_2021_05_06_trans.npz\n",
      "VR2_2021_05_06_trans.npz\n",
      "E:\\Zhong-et-2025\\spk\\DR10_2022_07_12_1_neural_data.npy\n",
      "DR10_2022_07_12_1_neural_data.npy\n",
      "E:\\Zhong-et-2025\\spk\\DR10_2022_07_19_1_neural_data.npy\n",
      "DR10_2022_07_19_1_neural_data.npy\n",
      "E:\\Zhong-et-2025\\spk\\DR10_2022_07_21_1_neural_data.npy\n",
      "DR10_2022_07_21_1_neural_data.npy\n",
      "E:\\Zhong-et-2025\\spk\\DR10_2022_07_28_1_neural_data.npy\n"
     ]
    }
   ],
   "source": [
    "root = r'E:\\Zhong-et-2025' # modify this to be your local folders, for example\n",
    "\n",
    "utils.download_data_from_figshare(root)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e156cef",
   "metadata": {},
   "source": [
    "## Data process\n",
    "### takes about 8 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment information for imaging mice\n",
    "exp_info = np.load(os.path.join(root, r'beh\\Imaging_Exp_info.npy'), allow_pickle=1).item()\n",
    "exp_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f06c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f52cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subfolder named \"process_data\" under root if it doesn't exist.\n",
    "proc_root = os.path.join(root, 'process_data')\n",
    "if not os.path.isdir(proc_root):\n",
    "    os.makedirs(proc_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsup_train1_before_learning\n"
     ]
    }
   ],
   "source": [
    "# get interpolational neural activity (neurons * trials * positions)\n",
    "# bins of positon: 60, each bin is 1 decimeter, total length of corridor is 6 meters \n",
    "\n",
    "for exp_type in exp_info.keys():\n",
    "    print(exp_type)\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    n = 1\n",
    "    for ndb in db:\n",
    "        if 'stimtype' in ndb.keys():\n",
    "            kn = '%s_%s_%s_%s'%(ndb['mname'], ndb['datexp'], ndb['blk'], ndb['stimtype'])\n",
    "        else:\n",
    "            kn = '%s_%s_%s'%(ndb['mname'], ndb['datexp'], ndb['blk'])\n",
    "        save_name = os.path.join(root, 'process_data', '%s_%s_%s_interpolate_spk.npy'%(ndb['mname'], ndb['datexp'], ndb['blk']))\n",
    "        if os.path.exists(save_name):\n",
    "            print(\"File has been created\")\n",
    "        else:    \n",
    "            beh = Beh[kn]\n",
    "            spk = utils.load_spk(ndb, root=os.path.join(root, 'spk'))\n",
    "            nneu, nfr = spk.shape  \n",
    "\n",
    "            ntrials, CL = beh['ntrials'], beh['Corridor_Length']    \n",
    "            VRmove = beh['ft_move'][:nfr]>0\n",
    "            ft_AcumPos = beh['ft_PosCum'][:nfr]\n",
    "\n",
    "            utils.get_interpPos_spk(spk[:, VRmove], ft_AcumPos[VRmove], ntrials, n_bins=60, \n",
    "                                    lengths=CL, save_path=save_name)\n",
    "        print('done %d'%(n))\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb06c2",
   "metadata": {},
   "source": [
    "## Get stimulus-selective index (dprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning', \n",
    "        'train1_before_grating',        'train1_after_grating', \n",
    "        \n",
    "        'naive_test1', 'unsup_train2_before_learning', 'sup_train2_before_learning', \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning',\n",
    "        \n",
    "        'naive_test1', 'unsup_train2_after_learning', 'sup_train2_after_learning',  'test1_after_grating']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], # leaf1 vs circle1\n",
    "           [2, 0], [2, 0],\n",
    "           [2, 0], [2, 0],\n",
    "          \n",
    "           [3, 0], [3, 0], [3, 0],  # leaf2 vs circle1\n",
    "           [3, 0], [3, 0],\n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "for exp_type, SID in zip(exps, Stim_ID):\n",
    "    print(exp_type)\n",
    "    print(SID)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item() # load behavior    \n",
    "    all_dat = utils.Get_dprime_selective_neuron(db, Beh, stim_ID=SID, root=root) # get dprime\n",
    "    # save the dprime\n",
    "    fn = '%s_%s_%s_dprime.npy'%(exp_type, stim[SID[0]], stim[SID[1]])\n",
    "    np.save(os.path.join(root, 'process_data', fn), all_dat)\n",
    "    print(fn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044100c6",
   "metadata": {},
   "source": [
    "## Get density map of stimulus-selective neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6525af",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning', \n",
    "        \n",
    "        'naive_test1', 'unsup_train2_before_learning', 'sup_train2_before_learning', \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning',\n",
    "        \n",
    "        'naive_test1', 'unsup_train2_after_learning', 'sup_train2_after_learning']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], # leaf1 vs circle1\n",
    "           [2, 0], [2, 0],\n",
    "          \n",
    "           [3, 0], [3, 0], [3, 0],  # leaf2 vs circle1\n",
    "           [3, 0], [3, 0],\n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "types = ['both', 'both', # include neurons selective to either leaf1 or circle1 in the case of leaf1 vs circle1\n",
    "         'both', 'both',\n",
    "        \n",
    "         'stim1', 'stim1', 'stim1', # include neurons selective to leaf1 in the case of leaf1 vs circle1\n",
    "         'stim1', 'stim1',\n",
    "        \n",
    "         'both', 'both', 'both']\n",
    "\n",
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "\n",
    "for exp_type, SID, typ in zip(exps, Stim_ID, types):\n",
    "    print(exp_type)\n",
    "    fn = '%s_%s_%s_dprime.npy'%(exp_type, stim[SID[0]], stim[SID[1]])\n",
    "    # load saved dprime\n",
    "    dprimes = np.load(os.path.join(root, 'process_data', fn), allow_pickle=1).item()\n",
    "    dprime, retinotopy = dprimes['dprime'], dprimes['retinotopy']\n",
    "\n",
    "    # get density map\n",
    "    sel_map = utils.Get_density_map(dprime, retinotopy, dp_thr=0.3, typ=typ)\n",
    "    if typ=='stim1':\n",
    "        saveN = fn.split('.')[0] + '_%s_distribution.npy'%(stim[SID[0]])\n",
    "    elif typ=='stim2':\n",
    "        saveN = fn.split('.')[0] + '_%s_distribution.npy'%(stim[SID[1]])\n",
    "    else:\n",
    "        saveN = fn.split('.')[0] + '_distribution.npy'\n",
    "    np.save(os.path.join(root, 'process_data', saveN), sel_map)\n",
    "    print(saveN)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc02036",
   "metadata": {},
   "source": [
    "## Percentage of stimulus-selective neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning', \n",
    "        'train1_before_grating',        'train1_after_grating', \n",
    "        \n",
    "        'unsup_train2_before_learning', 'sup_train2_before_learning', \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning',\n",
    "        \n",
    "        'naive_test1', 'unsup_train2_after_learning', 'sup_train2_after_learning',  'test1_after_grating']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], # leaf1 vs circle1\n",
    "           [2, 0], [2, 0],\n",
    "           [2, 0], [2, 0],\n",
    "          \n",
    "           [3, 0], [3, 0],  # leaf2 vs circle1\n",
    "           [3, 0], [3, 0],\n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "\n",
    "for exp_type, SID in zip(exps, Stim_ID):\n",
    "    print(exp_type)\n",
    "    fn = '%s_%s_%s_dprime.npy'%(exp_type, stim[SID[0]], stim[SID[1]])\n",
    "    \n",
    "    dprimes = np.load(os.path.join(root, 'process_data', fn), allow_pickle=1).item() # load saved dprime\n",
    "    dprime, retinotopy = dprimes['dprime'], dprimes['retinotopy']\n",
    "\n",
    "    frac = utils.Get_selective_neuron_fraction_with_dprime(dprime, retinotopy)\n",
    "    # save the fraction of selective neurons \n",
    "    saveN = fn.split('.')[0] + '_frac.npy'\n",
    "    np.save(os.path.join(root, 'process_data', saveN), frac)\n",
    "    print(saveN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01c9be",
   "metadata": {},
   "source": [
    "## Percentage and distribution of reward prediciton neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning']\n",
    "\n",
    "for exp_type in exps:\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    fn = '%s_leaf1_circle1_dprime.npy'%(exp_type)\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item() # load behavior\n",
    "    dprimes = np.load(os.path.join(root, 'process_data', fn), allow_pickle=1).item() # load saved stimulus selective dprime\n",
    "    frac, imgs = utils.Get_dprime_rewPred_neuron(db, Beh, dprimes, root=root, \n",
    "                                  load_save_interp_spk=1, interp_spk_path=os.path.join(root, 'process_data'), dp_thr=0.3)\n",
    "    # save the fraction of reward prediciton neurons \n",
    "    save_fn0 = '%s_rew_frac.npy'%(exp_type)\n",
    "    save_fn1 = '%s_rew_distribution.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn0), frac)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn1), imgs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618d7bc",
   "metadata": {},
   "source": [
    "## Coding direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "exps = ['naive_test1', 'unsup_test1', 'sup_test1', \n",
    "        \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning', 'test1_after_grating',\n",
    "        \n",
    "        'naive_test2', 'unsup_test2', 'sup_test2', 'test2_after_grating']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], [2, 0], # leaf1 vs circle1\n",
    "          \n",
    "           [2, 0], [2, 0], [2, 0],  \n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "for exp_type, SID in zip(exps, Stim_ID):\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "    dat = utils.Get_coding_direction(db, Beh, stim_ref=SID, prc=5, root=root, \n",
    "                                load_save_interp_spk=1, interp_spk_path=os.path.join(root, 'process_data'), n_bef=10)\n",
    "\n",
    "    save_fn = '%s_coding_direction.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn), dat)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff09329",
   "metadata": {},
   "source": [
    "## Positional tunning of stimulus-selective neurons, with train and test for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715483ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps = ['naive_test1', 'unsup_test1', 'sup_test1', 'naive_test3', 'unsup_test3', 'sup_test3']\n",
    "Stim_ID = [2, 0]# leaf1 vs circle1\n",
    "\n",
    "for exp_type in exps:\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "    dat = utils.Get_sort_spk(db, Beh, stim_ref=Stim_ID, prc=5, root=root, \n",
    "                                load_save_interp_spk=1, interp_spk_path=os.path.join(root, 'process_data'))\n",
    "    save_fn = '%s_sort_spk.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn), dat)\n",
    "    \n",
    "# use 1/2 of trials (train) for getting dprime to define stimulus selective neurons;\n",
    "# from the rest 1/2 trials, use half (tes1, 1/4 of total trials) to get and sort the peak positions\n",
    "# sort the last 1/4 trials (test2) by the sorted index from test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0afdc5",
   "metadata": {},
   "source": [
    "## Example stimulus selective neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Use 1/2 of trials (train) for getting dprime to define stimulus selective neurons;\n",
    "## 2. Return the activity of other 1/2 of trials (test) \n",
    "\n",
    "exp_type = 'sup_train1_after_learning' # type of experiment\n",
    "db = exp_info[exp_type] # get experiment information\n",
    "ndb = db[2]\n",
    "\n",
    "Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "dat = utils.get_stimNeu_and_sorted(ndb, Beh['%s_%s_%s'%(ndb['mname'], ndb['datexp'], ndb['blk'])], \n",
    "                             stim_ref=[2, 0], thr=0.3, root=root, load_save_interp_spk=1)\n",
    "save_fn = '%s_%s_%s_stimSelNeu_sorted.npy'%(ndb['mname'], ndb['datexp'], ndb['blk'])\n",
    "np.save(os.path.join(root, 'process_data', save_fn), dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c20109",
   "metadata": {},
   "source": [
    "## Reward prediction neural responses; with 10 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['sup_test1', 'sup_test2', 'sup_test3']\n",
    "for exp_type in exps:\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "\n",
    "    Beh = utils.load_exp_beh(root, exp_type)\n",
    "    dat = utils.get_kfold_reward_response(root, db, Beh)\n",
    "\n",
    "    save_fn = '%s_reward_response.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn), dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549c225",
   "metadata": {},
   "source": [
    "## Example reward prediction neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eeb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = 'sup_test1' # type of experiment\n",
    "db = exp_info[exp_type][-1] # get experiment information\n",
    "\n",
    "Beh = utils.load_exp_beh(root, exp_type)\n",
    "dat = utils.get_reward_neuorns(root, db, Beh['%s_%s_%s'%(db['mname'], db['datexp'], db['blk'])])\n",
    "\n",
    "save_fn = 'Example_reward_neurons_in_%s.npy'%(exp_type)\n",
    "np.save(os.path.join(root, 'process_data', save_fn), dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
