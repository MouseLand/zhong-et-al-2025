{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0ebf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unsup_train1_before_learning', 'unsup_train1_after_learning', 'sup_train1_before_learning', 'sup_train1_after_learning', 'unsup_test1', 'sup_test1', 'naive_test1', 'unsup_test2', 'sup_test2', 'naive_test2', 'unsup_test3', 'sup_test3', 'naive_test3', 'unsup_train2_before_learning', 'sup_train2_before_learning', 'unsup_train2_after_learning', 'sup_train2_after_learning', 'train1_before_grating', 'train1_after_grating', 'test1_before_grating', 'test1_after_grating', 'test2_before_grating', 'test2_after_grating'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import numpy as np\n",
    "import time\n",
    "root = r'D:\\Results\\Zhong-et-al-2025'\n",
    "\n",
    "# get experiment information of imaging mice\n",
    "exp_info = np.load(os.path.join(root, r'beh\\Imaging_Exp_info.npy'), allow_pickle=1).item()\n",
    "exp_info.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e156cef",
   "metadata": {},
   "source": [
    "### make sure you have 900GB space to save all processed data\n",
    "### takes about 8 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f06c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f52cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = r'D:\\Results\\Zhong-et-al-2025\\process_data'\n",
    "if not os.path.isdir(save_root):\n",
    "    os.makedirs(save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsup_train1_before_learning\n"
     ]
    }
   ],
   "source": [
    "# get interpolational neural activity (neurons * trials * positions)\n",
    "\n",
    "# bins of positon: 60, each bin is 1 decimeter, total length of corridor is 6 meters \n",
    "\n",
    "for exp_type in exp_info.keys():\n",
    "    print(exp_type)\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    n = 1\n",
    "    for ndb in db:\n",
    "        if 'stimtype' in ndb.keys():\n",
    "            kn = '%s_%s_%s_%s'%(ndb['mname'], ndb['datexp'], ndb['blk'], ndb['stimtype'])\n",
    "        else:\n",
    "            kn = '%s_%s_%s'%(ndb['mname'], ndb['datexp'], ndb['blk'])\n",
    "        save_name = os.path.join(root, 'process_data', '%s_%s_%s_interpolate_spk.npy'%(ndb['mname'], ndb['datexp'], ndb['blk']))\n",
    "        if os.path.exists(save_name):\n",
    "            print(\"File has been created\")\n",
    "        else:    \n",
    "            beh = Beh[kn]\n",
    "            spk = utils.load_spk(ndb, root=os.path.join(root, 'spk'))\n",
    "            nneu, nfr = spk.shape  \n",
    "\n",
    "            ntrials, CL = beh['ntrials'], beh['Corridor_Length']    \n",
    "            VRmove = beh['ft_move'][:nfr]>0\n",
    "            ft_AcumPos = beh['ft_PosCum'][:nfr]\n",
    "\n",
    "            utils.get_interpPos_spk(spk[:, VRmove], ft_AcumPos[VRmove], ntrials, n_bins=60, \n",
    "                                    lengths=CL, save_path=save_name)\n",
    "        print('done %d'%(n))\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb06c2",
   "metadata": {},
   "source": [
    "## Get stimulus-selective index (dprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for figure 1 and 3\n",
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning', \n",
    "        'train1_before_grating',        'train1_after_grating', \n",
    "        \n",
    "        'naive_test1', 'unsup_train2_before_learning', 'sup_train2_before_learning', \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning',\n",
    "        \n",
    "        'naive_test1', 'unsup_train2_after_learning', 'sup_train2_after_learning',  'test1_after_grating']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], # leaf1 vs circle1\n",
    "           [2, 0], [2, 0],\n",
    "           [2, 0], [2, 0],\n",
    "          \n",
    "           [3, 0], [3, 0], [3, 0],  # leaf2 vs circle1\n",
    "           [3, 0], [3, 0],\n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "for exp_type, SID in zip(exps, Stim_ID):\n",
    "    print(exp_type)\n",
    "    print(SID)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item() # load behavior    \n",
    "    all_dat = utils.Get_dprime_selective_neuron(db, Beh, stim_ID=SID, root=root) # get dprime\n",
    "    # save the dprime\n",
    "    fn = '%s_%s_%s_dprime.npy'%(exp_type, stim[SID[0]], stim[SID[1]])\n",
    "    np.save(os.path.join(root, 'process_data', fn), all_dat)\n",
    "    print(fn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044100c6",
   "metadata": {},
   "source": [
    "## Get density map of stimulus-selective neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6525af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for figure 1 and 3\n",
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning', \n",
    "        \n",
    "        'naive_test1', 'unsup_train2_before_learning', 'sup_train2_before_learning', \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning',\n",
    "        \n",
    "        'naive_test1', 'unsup_train2_after_learning', 'sup_train2_after_learning']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], # leaf1 vs circle1\n",
    "           [2, 0], [2, 0],\n",
    "          \n",
    "           [3, 0], [3, 0], [3, 0],  # leaf2 vs circle1\n",
    "           [3, 0], [3, 0],\n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "types = ['both', 'both', # include neurons selective to either leaf1 or circle1 in the case of leaf1 vs circle1\n",
    "         'both', 'both',\n",
    "        \n",
    "         'stim1', 'stim1', 'stim1', # include neurons selective to leaf1 in the case of leaf1 vs circle1\n",
    "         'stim1', 'stim1',\n",
    "        \n",
    "         'both', 'both', 'both']\n",
    "\n",
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "\n",
    "for exp_type, SID, typ in zip(exps, Stim_ID, types):\n",
    "    print(exp_type)\n",
    "    fn = '%s_%s_%s_dprime.npy'%(exp_type, stim[SID[0]], stim[SID[1]])\n",
    "    # load saved dprime\n",
    "    dprimes = np.load(os.path.join(root, 'process_data', fn), allow_pickle=1).item()\n",
    "    dprime, retinotopy = dprimes['dprime'], dprimes['retinotopy']\n",
    "\n",
    "    # get density map\n",
    "    sel_map = utils.Get_density_map(dprime, retinotopy, dp_thr=0.3, typ=typ)\n",
    "    if typ=='stim1':\n",
    "        saveN = fn.split('.')[0] + '_%s_distribution.npy'%(stim[SID[0]])\n",
    "    elif typ=='stim2':\n",
    "        saveN = fn.split('.')[0] + '_%s_distribution.npy'%(stim[SID[1]])\n",
    "    else:\n",
    "        saveN = fn.split('.')[0] + '_distribution.npy'\n",
    "    np.save(os.path.join(root, 'process_data', saveN), sel_map)\n",
    "    print(saveN)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc02036",
   "metadata": {},
   "source": [
    "## Percentage of stimulus-selective neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning', \n",
    "        'train1_before_grating',        'train1_after_grating', \n",
    "        \n",
    "        'unsup_train2_before_learning', 'sup_train2_before_learning', \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning',\n",
    "        \n",
    "        'naive_test1', 'unsup_train2_after_learning', 'sup_train2_after_learning',  'test1_after_grating']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], # leaf1 vs circle1\n",
    "           [2, 0], [2, 0],\n",
    "           [2, 0], [2, 0],\n",
    "          \n",
    "           [3, 0], [3, 0],  # leaf2 vs circle1\n",
    "           [3, 0], [3, 0],\n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "\n",
    "for exp_type, SID in zip(exps, Stim_ID):\n",
    "    print(exp_type)\n",
    "    fn = '%s_%s_%s_dprime.npy'%(exp_type, stim[SID[0]], stim[SID[1]])\n",
    "    \n",
    "    dprimes = np.load(os.path.join(root, 'process_data', fn), allow_pickle=1).item() # load saved dprime\n",
    "    dprime, retinotopy = dprimes['dprime'], dprimes['retinotopy']\n",
    "\n",
    "    frac = utils.Get_selective_neuron_fraction_with_dprime(dprime, retinotopy)\n",
    "    # save the fraction of selective neurons \n",
    "    saveN = fn.split('.')[0] + '_frac.npy'\n",
    "    np.save(os.path.join(root, 'process_data', saveN), frac)\n",
    "    print(saveN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01c9be",
   "metadata": {},
   "source": [
    "## Percentage and distribution of reward prediciton neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['unsup_train1_before_learning', 'unsup_train1_after_learning', \n",
    "        'sup_train1_before_learning',   'sup_train1_after_learning']\n",
    "\n",
    "for exp_type in exps:\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    fn = '%s_leaf1_circle1_dprime.npy'%(exp_type)\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item() # load behavior\n",
    "    dprimes = np.load(os.path.join(root, 'process_data', fn), allow_pickle=1).item() # load saved stimulus selective dprime\n",
    "    frac, imgs = utils.Get_dprime_rewPred_neuron(db, Beh, dprimes, root=root, \n",
    "                                  load_save_interp_spk=1, interp_spk_path=os.path.join(root, 'process_data'), dp_thr=0.3)\n",
    "    # save the fraction of reward prediciton neurons \n",
    "    save_fn0 = '%s_rew_frac.npy'%(exp_type)\n",
    "    save_fn1 = '%s_rew_distribution.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn0), frac)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn1), imgs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618d7bc",
   "metadata": {},
   "source": [
    "## Coding direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = ['circle1', 'circle2', 'leaf1', 'leaf2', 'leaf3']\n",
    "exps = ['naive_test1', 'unsup_test1', 'sup_test1', \n",
    "        \n",
    "        'unsup_train2_after_learning', 'sup_train2_after_learning', 'test1_after_grating',\n",
    "        \n",
    "        'naive_test2', 'unsup_test2', 'sup_test2', 'test2_after_grating']\n",
    "\n",
    "Stim_ID = [[2, 0], [2, 0], [2, 0], # leaf1 vs circle1\n",
    "          \n",
    "           [2, 0], [2, 0], [2, 0],  \n",
    "           \n",
    "           [2, 3], [2, 3], [2, 3], [2, 3]] #  leaf1 vs leaf2\n",
    "\n",
    "for exp_type, SID in zip(exps, Stim_ID):\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "    dat = utils.Get_coding_direction(db, Beh, stim_ref=SID, prc=5, root=root, \n",
    "                                load_save_interp_spk=1, interp_spk_path=os.path.join(root, 'process_data'), n_bef=10)\n",
    "\n",
    "    save_fn = '%s_coding_direction.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn), dat)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff09329",
   "metadata": {},
   "source": [
    "## Positional tunning of stimulus-selective neurons, with train and test for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715483ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps = ['naive_test1', 'unsup_test1', 'sup_test1', 'naive_test3', 'unsup_test3', 'sup_test3']\n",
    "Stim_ID = [2, 0]# leaf1 vs circle1\n",
    "\n",
    "for exp_type in exps:\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "    Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "    dat = utils.Get_sort_spk(db, Beh, stim_ref=Stim_ID, prc=5, root=root, \n",
    "                                load_save_interp_spk=1, interp_spk_path=os.path.join(root, 'process_data'))\n",
    "    save_fn = '%s_sort_spk.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn), dat)\n",
    "    \n",
    "# use 1/2 of trials (train) for getting dprime to define stimulus selective neurons;\n",
    "# from the rest 1/2 trials, use half (tes1, 1/4 of total trials) to get and sort the peak positions\n",
    "# sort the last 1/4 trials (test2) by the sorted index from test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0afdc5",
   "metadata": {},
   "source": [
    "## Example stimulus selective neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Use 1/2 of trials (train) for getting dprime to define stimulus selective neurons;\n",
    "## 2. Return the activity of other 1/2 of trials (test) \n",
    "\n",
    "exp_type = 'sup_train1_after_learning' # type of experiment\n",
    "db = exp_info[exp_type] # get experiment information\n",
    "ndb = db[2]\n",
    "\n",
    "Beh = np.load(os.path.join(root, 'beh', 'Beh_'+ exp_type+ '.npy'), allow_pickle=1).item()\n",
    "dat = utils.get_stimNeu_and_sorted(ndb, Beh['%s_%s_%s'%(ndb['mname'], ndb['datexp'], ndb['blk'])], \n",
    "                             stim_ref=[2, 0], thr=0.3, root=root, load_save_interp_spk=1)\n",
    "save_fn = '%s_%s_%s_stimSelNeu_sorted.npy'%(ndb['mname'], ndb['datexp'], ndb['blk'])\n",
    "np.save(os.path.join(root, 'process_data', save_fn), dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c20109",
   "metadata": {},
   "source": [
    "## Reward prediction neural responses; with 10 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['sup_test1', 'sup_test2', 'sup_test3']\n",
    "for exp_type in exps:\n",
    "    print(exp_type)\n",
    "    db = exp_info[exp_type] # get experiment information\n",
    "\n",
    "    Beh = utils.load_exp_beh(root, exp_type)\n",
    "    dat = utils.get_kfold_reward_response(root, db, Beh)\n",
    "\n",
    "    save_fn = '%s_reward_response.npy'%(exp_type)\n",
    "    np.save(os.path.join(root, 'process_data', save_fn), dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549c225",
   "metadata": {},
   "source": [
    "## Example reward prediction neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eeb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = 'sup_test1' # type of experiment\n",
    "db = exp_info[exp_type][-1] # get experiment information\n",
    "\n",
    "Beh = utils.load_exp_beh(root, exp_type)\n",
    "dat = utils.get_reward_neuorns(root, db, Beh['%s_%s_%s'%(db['mname'], db['datexp'], db['blk'])])\n",
    "\n",
    "save_fn = 'Example_reward_neurons_in_%s.npy'%(exp_type)\n",
    "np.save(os.path.join(root, 'process_data', save_fn), dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
